{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Epanagandla_Assignment5.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<center>\n",
        "\n",
        "# Assignment 5: Naive Bayes Learning\n",
        "\n",
        "</center>\n",
        "\n"
      ],
      "metadata": {
        "id": "u-Uh0vRIDHwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.About the model"
      ],
      "metadata": {
        "id": "mPuzMdfnDmw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naïve Bayes algorithm is a supervised learning algorithm, it is based on Bayes theorem. We use this algorithm mostly in classification problems such as text classification where we have high dimensional dataset. Here the prediction is based on probability of an object."
      ],
      "metadata": {
        "id": "Cw_YEBYIFX_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "P(A|B) = P(B|A).P(A)/P(B)\n",
        "\n",
        "Where, \n",
        "\n",
        "P(A): Prior probability i.e, probability of hypothesis before observing the evidence\n",
        "\n",
        "P(B): Marginal probability i.e., probability of evidence\n",
        "\n",
        "P(A|B): Evidence probability when hypothesis is true.  \n",
        "\n",
        "P(B|A): Hypothesis probability evidence is true."
      ],
      "metadata": {
        "id": "m8J6sreLGlVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spam filtration, Sentimental analysis, and classifying articles are some popular examples of Naive Bayes Algorithm."
      ],
      "metadata": {
        "id": "kWcQ_9u4IQcd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Dataset"
      ],
      "metadata": {
        "id": "ibd_lsg9IQx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a collection of customer reviews from six of the review topics used in the paper by Blitzer et al., (2007) mentioned above. Here we are formatting given data to make sure there is one review per line, and texts are split into lowercased separate words (\"tokens\"). \n",
        "\n",
        "url= http://www.cse.chalmers.se/~richajo/dit862/data/all_sentiment_shuffled.txt"
      ],
      "metadata": {
        "id": "AOPHGVo0IiJI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here necessary packages are imported along with requests package which allows you to send HTTP/1.1 requests easily."
      ],
      "metadata": {
        "id": "hpdwRUKjJD7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import requests"
      ],
      "metadata": {
        "id": "vKMMx6K8DFnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are obtaining data from URL and storing it in txt_data and then we are printing the data."
      ],
      "metadata": {
        "id": "D-nzm46uJZxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#obtaining data using requests package from URL\n",
        "rqst_url = requests.get ('http://www.cse.chalmers.se/~richajo/dit862/data/all_sentiment_shuffled.txt')\n",
        "txt_data = rqst_url.text\n",
        "txt_data"
      ],
      "metadata": {
        "id": "af24CQRBwEax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Data pre-processing"
      ],
      "metadata": {
        "id": "C4O0G0q7J9ms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are organizing this into columns\n",
        "\n",
        "•\t0: topic category label (books, camera, dvd, health, music, or software)\n",
        "\n",
        "•\t1: sentiment polarity label (pos or neg)\n",
        "\n",
        "•\t2: document identifier\n",
        "\n",
        "•\t3 and on: the words in the document\n"
      ],
      "metadata": {
        "id": "4fmxnL6UKHfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the columns\n",
        "label = []\n",
        "category= [] \n",
        "document_id_no = []\n",
        "review_of_words = []\n"
      ],
      "metadata": {
        "id": "acB_lrd_wgyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are splitting the data into the columns defined above"
      ],
      "metadata": {
        "id": "0sREo4LTKgiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for line in txt_data.splitlines():\n",
        "  label.append(line.split()[1])\n",
        "  category.append(line.split()[0])\n",
        "  document_id_no.append(line.split()[2])\n",
        "  review_of_words.append(' '.join(token for token in line.split()[3:]))"
      ],
      "metadata": {
        "id": "agLCU0TL33WK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here with the columns defined we are creating a data frame"
      ],
      "metadata": {
        "id": "cUbr37C_K0Ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataframe with columns ('label','category','document_id_no','review_of_words') \n",
        "df_txt = pd.DataFrame(zip(label,category,document_id_no,review_of_words ), columns = ['label','category','document_id_no','review_of_words'])"
      ],
      "metadata": {
        "id": "xIV8NXfK4fNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we are obtaining first 5 rows of the dataframe\n",
        "df_txt.head()"
      ],
      "metadata": {
        "id": "ZPdgl6k1KWXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are checking if there are any null values in the data"
      ],
      "metadata": {
        "id": "hcQipwigLULF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_txt.isnull().sum()"
      ],
      "metadata": {
        "id": "nv_3TE685pbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.Data visualization"
      ],
      "metadata": {
        "id": "5AyvFNi6L0D0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we are counting values in label column and printing it\n",
        "count_label = df_txt['label'].value_counts()\n",
        "count_label"
      ],
      "metadata": {
        "id": "Ch2nSag253jM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here for the negative and positive values in the column we are creating seaborn plot"
      ],
      "metadata": {
        "id": "gzlW3mrTMEOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data = df_txt, x = 'label')\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "PPG55Ufc6Udi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are replacing negative value with 0 and positive value with 1 and then we are converting str into int"
      ],
      "metadata": {
        "id": "GXnbUF6dMsxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_txt['label'] = np.where(df_txt['label']=='pos', 1, 0)\n",
        "df_txt"
      ],
      "metadata": {
        "id": "uh_eecye6Yet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.Splitting the data"
      ],
      "metadata": {
        "id": "tEbI9n-hNM7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are cleaning the data"
      ],
      "metadata": {
        "id": "OiYciae3wLDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stop_words"
      ],
      "metadata": {
        "id": "OMJcjHTXJAvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stop_words import get_stop_words\n",
        "#here we are removing 'en' words like i,were...etc\n",
        "stop_words = get_stop_words('en')\n",
        "# here we are Removing stopwords and numerics\n",
        "df_txt['review_of_words'] = df_txt['review_of_words'].apply( lambda x: ' '.join([x for x in str(x).split() if x not in stop_words]) )  \n",
        "# here we are removing punctuations and non-letter tokens\n",
        "df_txt['review_of_words']=df_txt['review_of_words'].str.replace('[^\\w\\s]','') "
      ],
      "metadata": {
        "id": "Z3kDFKesJCcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_txt['review_of_words'].head()"
      ],
      "metadata": {
        "id": "2SbpIMeRJGv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are importing the train_test_split module from sklearn package"
      ],
      "metadata": {
        "id": "VFE64DKdNTk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "z60dMUig8N7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are assigning words to x and labels to y "
      ],
      "metadata": {
        "id": "Yct3d982OuJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_txt['review_of_words']\n",
        "y = df_txt['label']"
      ],
      "metadata": {
        "id": "HS2Mblb-7Ucu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "splitting the data with test size as 20% and random state as 42"
      ],
      "metadata": {
        "id": "KFJx3mLnNeLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we are creating test and train data using train_test_split model with train size 80% & test size 20% along with random state as 42\n",
        "X_train, X_test, y_train, y_test = train_test_split (X, y, train_size = 0.8, random_state = 42)\n",
        "# Here we are obtaining train and test set shape\n",
        "print ('The Shapes of X_train, y_train: ', X_train.shape, y_train.shape)\n",
        "print ('The Shapes of X_test, y_test: ', X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "2_rJ2A3LNe3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.Applying the model"
      ],
      "metadata": {
        "id": "dS2PMlnoPsBz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we creating token count matrix from text document"
      ],
      "metadata": {
        "id": "GxiXsBoPUZkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(lowercase = False)"
      ],
      "metadata": {
        "id": "tXbvxzRr8PG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are fitting the vectorizer model for training data"
      ],
      "metadata": {
        "id": "09P90SRBVqug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tfrm = vectorizer.fit_transform(X_train)\n",
        "#Here we are creating dense matrix for train data\n",
        "X_train_tfrm_dnse_mtrx = X_train_tfrm.toarray()\n",
        "print ('The shape of transformed X_train: ', X_train_tfrm_dnse_mtrx.shape)\n",
        "print ('The shape of transformed y_train: ', y_train.shape)"
      ],
      "metadata": {
        "id": "oi2bIltr8SVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are fitting the vectorizer model for test data"
      ],
      "metadata": {
        "id": "OTlQeJqdV2Xo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_tfrm = vectorizer.transform(X_test)\n",
        "#Here we are creating dense matrix for test data\n",
        "X_test_tfrm_dnse_mtrx = X_test_tfrm.toarray()\n",
        "print ('The shape of transformed X_test: ', X_test_tfrm_dnse_mtrx.shape)\n",
        "print ('The shape of transformed y_test: ', y_test.shape)"
      ],
      "metadata": {
        "id": "vZTlZdE38XCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we are printing the length of the vectorizer feature names\n",
        "print('The total no. of features: ', len(vectorizer.get_feature_names()))"
      ],
      "metadata": {
        "id": "5AiVn2Qx8bHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are creating a Naive Bayes model for text classification"
      ],
      "metadata": {
        "id": "XVd8rPK6XuKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we are importing the multinomial naive bayes module from sklearn package\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "Multi_navie_bayes = MultinomialNB()\n",
        "# Here we are fitting the model into training set\n",
        "Multi_navie_bayes.fit(X_train_tfrm_dnse_mtrx, y_train)"
      ],
      "metadata": {
        "id": "c6MIjRk38bu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we are training and validating the model using k-fold cross validation\n",
        "from sklearn.model_selection import cross_validate\n",
        "cross_validte = cross_validate (Multi_navie_bayes, X_train_tfrm_dnse_mtrx, y_train, cv = 5)"
      ],
      "metadata": {
        "id": "9q8mQZAw8i3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.Prediction results and test scores"
      ],
      "metadata": {
        "id": "XW_cBGqkas5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are printing accuracy score for cv=5 and mean"
      ],
      "metadata": {
        "id": "b8dnk7j7bEc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"the accuracy score of 5-fold cross validation:\", cross_validte['test_score'])\n",
        "print(\"the cross validation accuracy mean score: \", cross_validte['test_score'].mean())"
      ],
      "metadata": {
        "id": "id7TRHqmZzs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = Multi_navie_bayes.predict(X_test_tfrm_dnse_mtrx)\n",
        "# Here we are evaluating the model on the test set\n",
        "print('the Accuracy of model in the test set : {:.3f}'.format(Multi_navie_bayes.score(X_test_tfrm_dnse_mtrx, y_test)))"
      ],
      "metadata": {
        "id": "SLiao9yz8nVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.Metrics"
      ],
      "metadata": {
        "id": "o4T7Oca9a2th"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are creating confusion matrix for y_test & y_train"
      ],
      "metadata": {
        "id": "2AH93Wp0cBJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cnfn_mtrx = confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "5R-36v2U8nbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are creating a image for confusion matrix heat map by using seaborn package"
      ],
      "metadata": {
        "id": "qckb2FjrcI2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(cnfn_mtrx, cmap=\"PuBuGn\", annot = True, fmt = '.0f')\n",
        "plt.xlabel ('The predicted values')\n",
        "plt.ylabel ('The actual values')\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "ehu_SB668xk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here by observing we can say that model is correct about 1007 negative reviews, 951 positive reviews but the model is incorrect about 194 positive reviews as negative and 229 negative reviews as positive."
      ],
      "metadata": {
        "id": "ocCVpKvOl8IE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Conclusion"
      ],
      "metadata": {
        "id": "JvXPhUbhiAsE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are using Receiver Operating Characteristic curve(ROC) it is a graph showing the performance of a classification model at all classification thresholds. The value of AUC is expected to be higher i.e., greater than 0.5 for the model to perform better.\n",
        "\n",
        "TPR and FPR are the probability that an actual positive will test positive and mistaken prediction of positive class\n",
        "\n",
        "   i.e., TPR = TP/P = TP/(TP+FN) and FPR = FP/N = FP/ (FP+TN)"
      ],
      "metadata": {
        "id": "JcuzxYOBl2DJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score"
      ],
      "metadata": {
        "id": "Sfvox37scQEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prb_1  = Multi_navie_bayes.predict_proba(X_test_tfrm_dnse_mtrx)[:,1]\n",
        "flse_ptve_rte, true_ptve_rte, threshold = roc_curve (y_test, y_pred_prb_1, pos_label = 1)\n",
        "roc_auc_score = roc_auc_score (y_test, y_pred_prb_1)\n",
        "print('The ROC AUC: ', roc_auc_score) "
      ],
      "metadata": {
        "id": "R5rdkSa08neX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we are visualizing the ROC Curve\n",
        "plt.plot (flse_ptve_rte, true_ptve_rte)\n",
        "plt.plot([0,1], '--')\n",
        "plt.xlabel ('False Postive Rate')\n",
        "plt.ylabel('True Postive Rate')\n",
        "plt.title (\"the ROC Curve (AUC = {:.3f})\".format(roc_auc_score))\n",
        "plt.grid()\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "VT5f_25r8nhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are plotting between true positive rate and false positive rate at different thresholds.\n",
        "## The ROC curve area is 0.884."
      ],
      "metadata": {
        "id": "sF70O9q1mqQi"
      }
    }
  ]
}